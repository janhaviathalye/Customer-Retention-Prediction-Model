{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b5a2fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T00:17:44.669554Z",
     "iopub.status.busy": "2024-12-05T00:17:44.669554Z",
     "iopub.status.idle": "2024-12-05T00:17:44.699815Z",
     "shell.execute_reply": "2024-12-05T00:17:44.699144Z"
    },
    "papermill": {
     "duration": 0.030261,
     "end_time": "2024-12-05T00:17:44.699815",
     "exception": false,
     "start_time": "2024-12-05T00:17:44.669554",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_data_path = \"test_dataset_bb67b6b30aa7405f9ee9762d2c05c3db.csv\"\n",
    "metrics_output_path = \"metrics_output.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac760e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T00:17:44.716888Z",
     "iopub.status.busy": "2024-12-05T00:17:44.716888Z",
     "iopub.status.idle": "2024-12-05T00:19:24.770064Z",
     "shell.execute_reply": "2024-12-05T00:19:24.769102Z"
    },
    "id": "S-jn9tcCULb3",
    "papermill": {
     "duration": 100.062697,
     "end_time": "2024-12-05T00:19:24.770064",
     "exception": false,
     "start_time": "2024-12-05T00:17:44.707367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: catboost in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: imbalanced-learn in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Requirement already satisfied: graphviz in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (3.9.3)\n",
      "Requirement already satisfied: pandas>=0.24 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: plotly in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (6.4.5)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.21.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'source' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: xgboost in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: lightgbm in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: catboost in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: imbalanced-learn in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: graphviz in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (3.9.3)\n",
      "Requirement already satisfied: plotly in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from matplotlib->catboost) (6.4.5)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.21.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: papermill in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: click in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (8.1.7)\n",
      "Requirement already satisfied: pyyaml in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (6.0.2)\n",
      "Requirement already satisfied: nbformat>=5.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (5.10.4)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (4.67.1)\n",
      "Requirement already satisfied: requests in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (2.32.3)\n",
      "Requirement already satisfied: entrypoints in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (0.4)\n",
      "Requirement already satisfied: tenacity>=5.0.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (9.0.0)\n",
      "Requirement already satisfied: ansicolors in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (1.1.8)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbclient>=0.2.0->papermill) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbclient>=0.2.0->papermill) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.4 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbclient>=0.2.0->papermill) (5.14.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbformat>=5.2.0->papermill) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbformat>=5.2.0->papermill) (4.23.0)\n",
      "Requirement already satisfied: colorama in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from tqdm>=4.32.2->papermill) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (2024.8.30)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.21.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (8.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (6.4.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbclient>=0.2.0->papermill) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbclient>=0.2.0->papermill) (308)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: nbformat in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: papermill in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: lightgbm in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: imbalanced-learn in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.9 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from flask) (8.5.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: pyyaml in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (6.0.2)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (4.67.1)\n",
      "Requirement already satisfied: requests in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (2.32.3)\n",
      "Requirement already satisfied: entrypoints in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (0.4)\n",
      "Requirement already satisfied: tenacity>=5.0.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (9.0.0)\n",
      "Requirement already satisfied: ansicolors in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from papermill) (1.1.8)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from importlib-metadata>=3.6->flask) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.21.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (308)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from nbclient>=0.2.0->papermill) (8.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from requests->papermill) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.2 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (6.4.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\myfiles\\uffall2023spring24fall24\\wicse\\shadowing program\\customer retention prediction model\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6353, number of negative: 6353\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3352\n",
      "[LightGBM] [Info] Number of data points in the train set: 12706, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters for LightGBM: {'classifier__subsample': 1.0, 'classifier__num_leaves': 50, 'classifier__n_estimators': 200, 'classifier__min_child_samples': 30, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.05, 'classifier__colsample_bytree': 0.8}\n",
      "Best cross-validated F1 score: 0.6270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Threshold: 0.47\n",
      "Max F1 Score on Test Data: 0.6172\n",
      "\n",
      "Optimized Model Performance on Test Data:\n",
      "Accuracy: 0.8400\n",
      "Precision: 0.5785\n",
      "Recall: 0.6615\n",
      "F1_score: 0.6172\n"
     ]
    }
   ],
   "source": [
    "#Customer Retention Prediction Model - AMEX Shadowing Program\n",
    "\n",
    "\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier # Bagging Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.linear_model import LogisticRegression # Import Logistic Regression Classifier\n",
    "from sklearn.svm import SVC # Import SVM classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "!pip install xgboost\n",
    "!pip install imbalanced-learn\n",
    "!pip install lightgbm catboost imbalanced-learn\n",
    "\n",
    "!source myenv/bin/activate  # Unix/MacOS\n",
    "\n",
    "!pip install numpy pandas scikit-learn xgboost lightgbm catboost imbalanced-learn\n",
    "\n",
    "!pip install papermill\n",
    "\n",
    "!pip install flask nbformat papermill lightgbm imbalanced-learn scikit-learn\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing and modeling\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Suppress warnings (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------------\n",
    "# Parameters\n",
    "test_data_path = 'Churn_Modelling_Test.csv'  # Default value, overridden by papermill\n",
    "metrics_output_path = 'metrics_output.json'  # Default value, overridden by papermill\n",
    "\n",
    "# Feature Engineering Function\n",
    "def add_features(data):\n",
    "    data['BalanceSalaryRatio'] = data['Balance'] / (data['EstimatedSalary'] + 1)\n",
    "    data['CreditScoreAgeRatio'] = data['CreditScore'] / (data['Age'] + 1)\n",
    "    data['TenureByAge'] = data['Tenure'] / (data['Age'] + 1)\n",
    "    data['AgeBalanceInteraction'] = data['Age'] * data['Balance']\n",
    "    data['HasCrCardAndActive'] = data['HasCrCard'] * data['IsActiveMember']\n",
    "    return data\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('Churn_Modelling_Train.csv')\n",
    "test_data = pd.read_csv(test_data_path)  # Use the parameter for test data path\n",
    "\n",
    "# Add features\n",
    "train_data = add_features(train_data)\n",
    "test_data = add_features(test_data)\n",
    "\n",
    "# Preprocess data function\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     # Keep CustomerId and Surname separately\n",
    "#     # customer_info = data[['CustomerId', 'Surname']].copy()\n",
    "    \n",
    "#     # Drop unnecessary columns\n",
    "#     data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, errors='ignore')\n",
    "    \n",
    "#     X = data.drop('Exited', axis=1)\n",
    "#     y = data['Exited']\n",
    "    \n",
    "#     return X, y\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     # Keep CustomerId and Surname separately\n",
    "#     customer_info = data[['CustomerId', 'Surname']].copy()\n",
    "    \n",
    "#     # Drop unnecessary columns\n",
    "#     data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, errors='ignore')\n",
    "    \n",
    "#     X = data.drop('Exited', axis=1)\n",
    "#     y = data['Exited']\n",
    "    \n",
    "#     return X, y, customer_info\n",
    "\n",
    "# # X_train_raw, y_train_raw = preprocess_data(train_data)\n",
    "# # X_test_raw, y_test = preprocess_data(test_data)\n",
    "\n",
    "# # Preprocess data\n",
    "# X_train_raw, y_train_raw, _ = preprocess_data(train_data)  # The underscore (_) ignores the third returned value for training data\n",
    "# X_test_raw, y_test, test_customers = preprocess_data(test_data)  # Assign the third returned value to test_customers\n",
    "\n",
    "# Preprocess data function\n",
    "def preprocess_data(data):\n",
    "    # Keep CustomerId and Surname separately\n",
    "    customer_info = data[['CustomerId', 'Surname']].copy()\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, errors='ignore')\n",
    "    \n",
    "    X = data.drop('Exited', axis=1)\n",
    "    y = data['Exited']\n",
    "    \n",
    "    return X, y, customer_info\n",
    "\n",
    "# Preprocess data\n",
    "X_train_raw, y_train_raw, _ = preprocess_data(train_data)  # Ignore customer_info for training data\n",
    "X_test_raw, y_test, test_customers = preprocess_data(test_data)  # Capture customer_info for test data\n",
    "\n",
    "\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = ['Geography', 'Gender']\n",
    "numerical_cols = [col for col in X_train_raw.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model (LightGBM)\n",
    "lgb_classifier = lgb.LGBMClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Simplified hyperparameter grid\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__num_leaves': [31, 50],\n",
    "    'classifier__min_child_samples': [20, 30],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Custom scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42, k_neighbors=5)),\n",
    "    ('classifier', lgb_classifier)\n",
    "])\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Randomized Search\n",
    "n_iter_search = 20  # Number of parameter settings that are sampled\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iter_search,\n",
    "    cv=cv,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "# Best estimator\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"Best parameters for LightGBM: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validated F1 score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Transform the test data using the fitted preprocessor from the pipeline\n",
    "X_test_transformed = best_model.named_steps['preprocessor'].transform(X_test_raw)\n",
    "\n",
    "# Predict probabilities on test data\n",
    "y_probs = best_model.named_steps['classifier'].predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# Optimize threshold\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "f1_scores = [f1_score(y_test, (y_probs >= t).astype(int)) for t in thresholds]\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "max_f1_score = max(f1_scores)\n",
    "\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"Max F1 Score on Test Data: {max_f1_score:.4f}\")\n",
    "\n",
    "# Final predictions\n",
    "y_pred_optimal = (y_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "test_customers['Exited_Predicted'] = y_pred_optimal\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test, y_pred_optimal)\n",
    "precision_test = precision_score(y_test, y_pred_optimal)\n",
    "recall_test = recall_score(y_test, y_pred_optimal)\n",
    "f1_test = f1_score(y_test, y_pred_optimal)\n",
    "\n",
    "print(f\"\\nOptimized Model Performance on Test Data:\")\n",
    "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1_score: {f1_test:.4f}\")\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_test,\n",
    "    'Precision': precision_test,\n",
    "    'Recall': recall_test,\n",
    "    'F1_score': f1_test\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(metrics_output_path, 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "\n",
    "# Filter customers who exited\n",
    "exited_customers = test_customers[test_customers['Exited_Predicted'] == 1][['CustomerId', 'Surname']]\n",
    "exited_customers.to_json('exited_customers.json', orient = 'records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c555e15",
   "metadata": {
    "id": "clKZfzEFUAgo",
    "papermill": {
     "duration": 0.010017,
     "end_time": "2024-12-05T00:19:24.784596",
     "exception": false,
     "start_time": "2024-12-05T00:19:24.774579",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.889328,
   "end_time": "2024-12-05T00:19:26.026947",
   "environment_variables": {},
   "exception": null,
   "input_path": "Customer_Retention_Prediction_Model.ipynb",
   "output_path": "output1.ipynb",
   "parameters": {
    "metrics_output_path": "metrics_output.json",
    "test_data_path": "test_dataset_bb67b6b30aa7405f9ee9762d2c05c3db.csv"
   },
   "start_time": "2024-12-05T00:17:41.137619",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}